{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "685ecc82",
   "metadata": {},
   "source": [
    "### Confuguring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd63a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "output = model.invoke(\"Hi\")\n",
    "output = output.content\n",
    "print(output)\n",
    "# so LLM - google model is working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd78cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83406d7e",
   "metadata": {},
   "source": [
    "### configuring the embedding model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59fc8add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\agenticbatch2\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")\n",
    "output = len(embeddings.embed_query(\"Hi\"))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4267e01",
   "metadata": {},
   "source": [
    "### Create a Vector Database - take a embedd it and store in vector dayttbase - need documentLoder,Vector db(croma) and then split into the chunck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e38aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader,DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ced29f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1005.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"ðŸ‡ºðŸ‡¸ Overview of the U.S. Economy\\nThe United States of America possesses the largest economy in the world in terms of nominal GDP, making it the most powerful economic force globally. It operates under a capitalist mixed economy, where the private sector dominates, but the government plays a significant regulatory and fiscal role. With a population of over 335 million people and a high level of technological advancement, the U.S. economy thrives on a foundation of consumer spending, innovation, global trade, and financial services. It has a highly diversified structure with strong sectors in technology, healthcare, finance, real estate, defense, and agriculture.\\n\\nU.S. GDP â€“ Size, Composition, and Global Share\\nAs of 2024, the United Statesâ€™ nominal GDP is estimated to be around $28 trillion USD, accounting for approximately 25% of the global economy. It ranks #1 in the world by nominal GDP, far ahead of China (which ranks 2nd). The U.S. GDP per capita is also among the highest, hovering around $83,000, which indicates a high standard of living and productivity. In terms of Purchasing Power Parity (PPP), the U.S. ranks second, but nominal GDP is considered more reflective of actual economic size and financial influence.\\n\\nThe GDP is predominantly driven by the services sector, which contributes more than 77% to the total GDP. This includes industries such as finance, insurance, real estate, healthcare, education, and information technology. The industrial sector (manufacturing, construction, mining) makes up around 19%, while agriculture, although technologically advanced and export-oriented, contributes only about 1%. Despite its small share in GDP, U.S. agriculture is globally significant in terms of productivity and exports.\\n\\nGDP Growth Trends and Dynamics\\nHistorically, the U.S. economy has enjoyed consistent long-term growth, averaging around 2-3% annually. Post-pandemic, the economy bounced back strongly, but 2022 and 2023 saw rising inflation due to supply chain issues and stimulus-driven demand. In 2024, the U.S. GDP grew at a modest pace of around 2.1%, as the Federal Reserveâ€™s interest rate hikes aimed at controlling inflation also moderated economic expansion. Consumer spending, which makes up nearly 70% of GDP, remains a dominant force in economic stability.\\n\\nThe U.S. maintains its GDP growth through strong innovation, entrepreneurship, and investment in R&D. With companies like Apple, Google, Amazon, Microsoft, and Tesla leading global markets, the U.S. consistently produces high value across sectors, especially in technology and advanced services. Additionally, the economy benefits from intellectual property exports, financial services, and higher education, all of which contribute significantly to GDP through both domestic and international markets.\\n\\nRole in the Global Economy\\nThe U.S. Dollar (USD) is the global reserve currency, held by over 60% of the worldâ€™s central bank reserves. This gives the U.S. an enormous advantage in global trade and borrowing. The U.S. is a key member of international institutions like the World Bank, IMF, G7, G20, and WTO, and plays a central role in setting global economic policy.\\n\\nAs a global innovation hub, the U.S. attracts billions in foreign investment and hosts many of the world's largest and most valuable companies. Its exports include high-tech machinery, aircraft, pharmaceuticals, semiconductors, and financial services, while its imports cover consumer goods, electronics, automobiles, and industrial materials. The trade deficit remains large (around $900 billion in 2024), primarily because the U.S. consumes more than it exports, but its ability to finance this through capital inflows and reserve currency status sustains balance.\\n\\nKey Economic Strengths\\nThe core strength of the U.S. economy lies in its flexible labor market, deep capital markets, technological superiority, and legal system that encourages innovation and property rights. It has a large, highly educated workforce, a diverse immigration pipeline, and access to vast natural resources including oil, gas, coal, and farmland. The presence of top-tier universities and research institutions fuels the knowledge economy, with billions spent annually on R&Dâ€”over $700 billion USD, more than any other country.\\n\\nThe U.S. leads in many critical sectors, including software, biotechnology, aerospace, defense, financial services, and media. Its startup ecosystem, especially in Silicon Valley, produces unicorns and tech giants at a scale unmatched globally. Its financial marketsâ€”particularly Wall Streetâ€”are the most liquid and globally integrated in the world.\\n\\nChallenges and Structural Issues\\nDespite its strength, the U.S. economy faces several serious long-term issues. The national debt has surpassed $34 trillion USD, raising concerns about fiscal sustainability, especially as interest payments alone are growing rapidly. The income and wealth inequality gap has widened, with a small percentage of Americans owning a disproportionate share of wealth. Access to affordable healthcare, housing shortages, and a declining labor force participation in some sectors are additional structural issues.\\n\\nAnother growing concern is political polarization, which often stalls crucial economic reforms and budget agreements, as seen in recurrent debt ceiling crises. The U.S. also faces challenges from global competition, especially from China in areas like AI, semiconductors, and green technology. Moreover, climate change, cybersecurity threats, and geopolitical risks (like Ukraine and Taiwan conflicts) add layers of vulnerability to economic planning.\\n\\nFuture Outlook (2025â€“2030)\\nLooking forward, the U.S. economy is expected to grow at a moderate pace, powered by innovation in AI, green energy, robotics, biotech, and quantum computing. The Biden administrationâ€™s Inflation Reduction Act and CHIPS Act are pumping massive investments into semiconductors, clean energy, and infrastructure. There is a strong push for reshoring of manufacturing, especially in critical sectors like chips, pharmaceuticals, and batteries.\\n\\nHowever, economic leadership will depend on managing the national debt, reforming entitlement programs, upgrading infrastructure, and ensuring the next generation is equipped with digital-age skills. If the U.S. can handle these challenges, it is well-positioned to remain a global economic powerhouse through 2030 and beyond.\\n\\nFinal Summary\\nThe U.S. economy remains the engine of global growth, backed by unmatched innovation, financial dominance, and a strong institutional framework. Its $28 trillion GDP and influence over global finance, trade, and technology make it the centerpiece of the modern economic system. Yet, rising debt, inequality, political gridlock, and competition from emerging powers demand careful policy navigation. If successfully addressed, the U.S. will continue to dominate the global economy well into the future.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    \"../data2\",\n",
    "    glob=\"**/*.txt\",\n",
    "    show_progress=True,\n",
    "    loader_cls=TextLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a9a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_spitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94aee738",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_docs = text_spitter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d6bc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_string = [documents.page_content for documents in new_docs]\n",
    "\n",
    "#numbers = [1, 2, 3, 4, 5]List comprehension in Python\n",
    "#squared = [num ** 2 for num in numbers]\n",
    "#print(squared)  # Output: [1, 4, 9, 16, 25]\n",
    "# done \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b51e0ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_string)\n",
    "# 55 file chinc are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5280057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86eac0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=Chroma.from_documents(new_docs,embeddings)# store data inside a crome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88bedc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retereiverdb = db.as_retriever(search_kwargs={\"k\": 3})# reteiver from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b124381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data2\\\\usa.txt'}, page_content='ðŸ‡ºðŸ‡¸ Overview of the U.S. Economy'),\n",
       " Document(metadata={'source': '..\\\\data2\\\\usa.txt'}, page_content='Looking forward, the U.S. economy is expected to grow at a moderate pace, powered by innovation in AI, green energy, robotics, biotech, and quantum computing. The Biden administrationâ€™s Inflation'),\n",
       " Document(metadata={'source': '..\\\\data2\\\\usa.txt'}, page_content='The U.S. economy remains the engine of global growth, backed by unmatched innovation, financial dominance, and a strong institutional framework. Its $28 trillion GDP and influence over global')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retereiverdb.invoke(\"Industrial growth of USA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243aa8bd",
   "metadata": {},
   "source": [
    "#### Langgrapg workflow creation  - creation of Pydentoic class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c94eb001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import List\n",
    "from pydantic import BaseModel , Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.output_parsers import PydanticOutputParser,StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "import operator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e770cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic: str = Field(description=\"The topic selected by the user\")\n",
    "    Reasoning: str = Field(description=\"The reasoning behind the topic selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a0deb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "PydanticOutputParser = PydanticOutputParser(pydantic_object=TopicSelectionParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbbe2051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"The topic selected by the user\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"The reasoning behind the topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PydanticOutputParser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7db344cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"The topic selected by the user\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"The reasoning behind the topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"The topic selected by the user\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"The reasoning behind the topic selection\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f873cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage],operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef7f89f",
   "metadata": {},
   "source": [
    "### Explaing the above code\n",
    "### Dictionary -AgentState={}, inside dic created one key messages as AgentState[\"messages\"] and assihn messige list =[]\n",
    "### AgentState[\"messages\"]=[]\n",
    "### AgentState[\"messages\"].append(message)\n",
    "### AgentState[\"messages\"] = AgentState[\"messages\"] + [message]\n",
    "### AgentState[\"messages\"] += [message]\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d9fd7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.AgentState['BaseMessage']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AgentState[\"BaseMessage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "129e163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(state:AgentState):\n",
    "    question = state[\"messages\"][-1]\n",
    "    print(\"Question\", question)\n",
    "    template = \"\"\"\n",
    "        Your task is to classify the given user query into one of the following categories: [USA,Not Related]. \n",
    "        Only respond with the category name and nothing else.\n",
    "\n",
    "        User query: {question}\n",
    "        {format_instructions}\n",
    "        \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"question\"],\n",
    "        partial_variables={\"format_instructions\": PydanticOutputParser.get_format_instructions()}\n",
    "    )\n",
    "    chain = prompt | model | PydanticOutputParser\n",
    "    response = chain.invoke({\"question\": \"Industrial growth of USA\"})\n",
    "    print(\"Parsed response:\", response)\n",
    "    return {\"messages\": [response.Topic]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b28084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "368a2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc86391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(state:AgentState):\n",
    "    print(\"-> RAG Call ->\")\n",
    "    \n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    prompt=PromptTemplate(\n",
    "        template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
    "        \n",
    "        input_variables=['context', 'question']\n",
    "    )\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retereiverdb | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = rag_chain.invoke(question)\n",
    "    return  {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa68e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Function\n",
    "def function_3(state:AgentState):\n",
    "    print(\"-> LLM Call ->\")\n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    # Normal LLM call\n",
    "    complete_query = \"Anwer the follow question with you knowledge of the real world. Following is the user question: \" + question\n",
    "    response = model.invoke(complete_query)\n",
    "    return {\"messages\": [response.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "587f8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state:AgentState):\n",
    "    print(\"-> ROUTER ->\")\n",
    "    \n",
    "    last_message=state[\"messages\"][-1]\n",
    "    print(\"last_message:\", last_message)\n",
    "    \n",
    "    if \"usa\" in last_message.lower():\n",
    "        return \"RAG Call\"\n",
    "    else:\n",
    "        return \"LLM Call\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "193b2d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### State graph\n",
    "workflow = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "762ea246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27e95a57fb0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"Supervise\",function_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c5bb282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Node `RAG` already present.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_node\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRAG\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfunction_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\agenticbatch2\\myenv\\Lib\\site-packages\\langgraph\\graph\\state.py:375\u001b[39m, in \u001b[36mStateGraph.add_node\u001b[39m\u001b[34m(self, node, action, defer, metadata, input, retry, cache_policy, destinations)\u001b[39m\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` already present.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node == END \u001b[38;5;129;01mor\u001b[39;00m node == START:\n\u001b[32m    377\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` is reserved.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Node `RAG` already present."
     ]
    }
   ],
   "source": [
    "workflow.add_node(\"RAG\",function_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f97fb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27e95a57fb0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"LLM\",function_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37c1b427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27e95a57fb0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_entry_point(\"Supervise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49443dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27e95a57fb0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_conditional_edges(\n",
    "    \"Supervise\",\n",
    "    router,\n",
    "    {\n",
    "        \"RAG\": \"RAG\",\n",
    "        \"LLM\": \"LLM\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bab16b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27e95a57fb0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"RAG\",END)\n",
    "workflow.add_edge(\"LLM\",END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e7345c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b7748f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b75643fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state={\"messages\":[\"hi\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd5197ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question hi\n",
      "Parsed response: Topic='USA' Reasoning='The query explicitly mentions the industrial growth of the USA.'\n",
      "-> ROUTER ->\n",
      "last_message: USA\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'RAG Call'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\agenticbatch2\\myenv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\agenticbatch2\\myenv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\agenticbatch2\\myenv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    159\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\agenticbatch2\\myenv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\agenticbatch2\\myenv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:625\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m    624\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\agenticbatch2\\myenv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\agenticbatch2\\myenv\\Lib\\site-packages\\langgraph\\graph\\branch.py:174\u001b[39m, in \u001b[36mBranch._route\u001b[39m\u001b[34m(self, input, config, reader, writer)\u001b[39m\n\u001b[32m    172\u001b[39m     value = \u001b[38;5;28minput\u001b[39m\n\u001b[32m    173\u001b[39m result = \u001b[38;5;28mself\u001b[39m.path.invoke(value, config)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\agenticbatch2\\myenv\\Lib\\site-packages\\langgraph\\graph\\branch.py:210\u001b[39m, in \u001b[36mBranch._finish\u001b[39m\u001b[34m(self, writer, input, result, config)\u001b[39m\n\u001b[32m    207\u001b[39m     result = [result]\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ends:\n\u001b[32m    209\u001b[39m     destinations: Sequence[Union[Send, \u001b[38;5;28mstr\u001b[39m]] = [\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m         r \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r, Send) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mends\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[32m    211\u001b[39m     ]\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    213\u001b[39m     destinations = cast(Sequence[Union[Send, \u001b[38;5;28mstr\u001b[39m]], result)\n",
      "\u001b[31mKeyError\u001b[39m: 'RAG Call'",
      "During task with name 'Supervisor' and id 'd033fc2f-15de-2f40-f035-c0a682396fd9'"
     ]
    }
   ],
   "source": [
    "app.invoke({\"messages\":[\"hi\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e04c775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
